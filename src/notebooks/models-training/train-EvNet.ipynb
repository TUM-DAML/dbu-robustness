{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/charpent/dbu-robustness/src/notebooks/models-training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.evidential_networks.run import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "use_cuda=True\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=123\n",
    "dataset_name='MNIST'\n",
    "ood_dataset_names=['KMNIST', 'FMNIST']\n",
    "split=[.8, .2]\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='../saved-models'\n",
    "architecture='conv'\n",
    "input_dims=[28, 28, 1]\n",
    "output_dim=10\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=5\n",
    "k_lipschitz=None\n",
    "\n",
    "# Training parameters\n",
    "directory_results='../saved-results'\n",
    "max_epochs=10\n",
    "patience=5\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=1e-4\n",
    "loss='UMSE'\n",
    "adversarial_training = None\n",
    "rs_sigma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-08 16:08:05 (INFO): Received the following configuration:\n",
      "2021-06-08 16:08:05 (INFO): DATASET | seed_dataset 123 - dataset_name MNIST - ood_dataset_names ['KMNIST', 'FMNIST'] - split [0.8, 0.2]\n",
      "2021-06-08 16:08:05 (INFO): ARCHITECTURE |  seed_model 123 -  architecture conv -  input_dims [28, 28, 1] -  output_dim 10 -  hidden_dims [64, 64, 64] -  kernel_dim 5 -  k_lipschitz None\n",
      "2021-06-08 16:08:05 (INFO): TRAINING |  max_epochs 10 -  patience 5 -  frequency 2 -  batch_size 64 -  lr 0.0001 -  loss UMSE\n",
      "2021-06-08 16:08:05 (INFO): shared: {'attack_name': 'PGD_L2', 'attack_loss': 'crossentropy', 'bounds': [0.0, 1.0], 'criterion_params': {'threshold': None, 'start_data': 'in'}, 'attack_params': {'epsilons': [1.0], 'loss_name': 'crossentropy', 'punished_measure': None, 'data_type': 'in'}, 'attack_kwargs': {'steps': 5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 111.362 | Val Acc.: 0.931\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 1.39 | Val Acc.: 0.939\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 1.016 | Val Acc.: 0.945\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 0.987 | Val Acc.: 0.949\n",
      "Model saved\n",
      "Epoch 8 -> Val loss 0.98 | Val Acc.: 0.952\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "results = run(\n",
    "        # Dataset parameters\n",
    "        seed_dataset,  # Seed to shuffle dataset. int\n",
    "        dataset_name,  # Dataset name. string\n",
    "        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "        split,  # Split for train/val/test sets. list of floats\n",
    "\n",
    "        # Architecture parameters\n",
    "        seed_model,  # Seed to init model. int\n",
    "        directory_model,  # Path to save model. string\n",
    "        architecture,  # Encoder architecture name. string\n",
    "        input_dims,  # Input dimension. List of ints\n",
    "        output_dim,  # Output dimension. int\n",
    "        hidden_dims,  # Hidden dimensions. list of ints\n",
    "        kernel_dim,  # Input dimension. int\n",
    "        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "\n",
    "        # Training parameters\n",
    "        directory_results,  # Path to save resutls. string\n",
    "        max_epochs,  # Maximum number of epochs for training\n",
    "        patience,  # Patience for early stopping. int\n",
    "        frequency,  # Frequency for early stopping test. int\n",
    "        batch_size,  # Batch size. int\n",
    "        lr,  # Learning rate. float\n",
    "        loss,  # Loss name. string\n",
    "        adversarial_training,\n",
    "        rs_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '../saved-models/model-evn-123-MNIST-[0.8, 0.2]-123-conv-[28, 28, 1]-10-[64, 64, 64]-5-None-10-5-2-64-0.0001-UMSE-None-None',\n",
       " 'result_path': '../saved-results/results-evn-123-MNIST-[0.8, 0.2]-123-conv-[28, 28, 1]-10-[64, 64, 64]-5-None-10-5-2-64-0.0001-UMSE-None-None',\n",
       " 'train_losses': [],\n",
       " 'val_losses': [-31668.213354166666,\n",
       "  1.2818773295084636,\n",
       "  1.0145267028808593,\n",
       "  0.9878273315429688,\n",
       "  0.9810649719238281],\n",
       " 'train_accuracies': [],\n",
       " 'val_accuracies': [0.9160833358764648,\n",
       "  0.9051666855812073,\n",
       "  0.9084166884422302,\n",
       "  0.9110000133514404,\n",
       "  0.9164999723434448],\n",
       " 'fail_trace': <function seml.evaluation.get_results(db_collection_name, fields=None, to_data_frame=False, mongodb_config=None, states=None, filter_dict=None, parallel=False)>,\n",
       " 'accuracy': array(0.9215),\n",
       " 'confidence_aleatoric_apr': 0.9913926596147168,\n",
       " 'confidence_epistemic_apr': 0.9658982964022087,\n",
       " 'confidence_aleatoric_auroc': 0.911859851875404,\n",
       " 'confidence_epistemic_auroc': 0.7161167578477351,\n",
       " 'brier_score': array(0.1860219, dtype=float32),\n",
       " 'anomaly_detection_aleatoric_KMNIST_apr': 0.833931634076325,\n",
       " 'anomaly_detection_epistemic_KMNIST_apr': 0.6580883344858652,\n",
       " 'anomaly_detection_aleatoric_KMNIST_auroc': 0.82015266,\n",
       " 'anomaly_detection_epistemic_KMNIST_auroc': 0.642154095,\n",
       " 'anomaly_detection_aleatoric_FMNIST_apr': 0.7860489231163297,\n",
       " 'anomaly_detection_epistemic_FMNIST_apr': 0.5186493234893362,\n",
       " 'anomaly_detection_aleatoric_FMNIST_auroc': 0.774408935,\n",
       " 'anomaly_detection_epistemic_FMNIST_auroc': 0.5341594}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=123\n",
    "dataset_name='MNIST'\n",
    "ood_dataset_names=['KMNIST', 'FMNIST']\n",
    "split=[.8, .2]\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='../saved-models'\n",
    "architecture='conv'\n",
    "input_dims=[28, 28, 1]\n",
    "output_dim=10\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=5\n",
    "k_lipschitz=None\n",
    "\n",
    "# Training parameters\n",
    "directory_results='../saved-results'\n",
    "max_epochs=10\n",
    "patience=5\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=1e-4\n",
    "loss='UMSE'\n",
    "adversarial_training = None\n",
    "rs_sigma = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-08 15:47:31 (INFO): Received the following configuration:\n",
      "2021-06-08 15:47:31 (INFO): DATASET | seed_dataset 123 - dataset_name MNIST - ood_dataset_names ['KMNIST', 'FMNIST'] - split [0.8, 0.2]\n",
      "2021-06-08 15:47:31 (INFO): ARCHITECTURE |  seed_model 123 -  architecture conv -  input_dims [28, 28, 1] -  output_dim 10 -  hidden_dims [64, 64, 64] -  kernel_dim 5 -  k_lipschitz None\n",
      "2021-06-08 15:47:31 (INFO): TRAINING |  max_epochs 10 -  patience 5 -  frequency 2 -  batch_size 64 -  lr 0.0001 -  loss UMSE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 83.006 | Val Acc.: 0.919\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 1.281 | Val Acc.: 0.895\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 1.015 | Val Acc.: 0.909\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 0.986 | Val Acc.: 0.917\n",
      "Model saved\n",
      "Epoch 8 -> Val loss 0.981 | Val Acc.: 0.921\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "results = run(\n",
    "        # Dataset parameters\n",
    "        seed_dataset,  # Seed to shuffle dataset. int\n",
    "        dataset_name,  # Dataset name. string\n",
    "        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "        split,  # Split for train/val/test sets. list of floats\n",
    "\n",
    "        # Architecture parameters\n",
    "        seed_model,  # Seed to init model. int\n",
    "        directory_model,  # Path to save model. string\n",
    "        architecture,  # Encoder architecture name. string\n",
    "        input_dims,  # Input dimension. List of ints\n",
    "        output_dim,  # Output dimension. int\n",
    "        hidden_dims,  # Hidden dimensions. list of ints\n",
    "        kernel_dim,  # Input dimension. int\n",
    "        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "\n",
    "        # Training parameters\n",
    "        directory_results,  # Path to save resutls. string\n",
    "        max_epochs,  # Maximum number of epochs for training\n",
    "        patience,  # Patience for early stopping. int\n",
    "        frequency,  # Frequency for early stopping test. int\n",
    "        batch_size,  # Batch size. int\n",
    "        lr,  # Learning rate. float\n",
    "        loss,  # Loss name. string\n",
    "        adversarial_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '../saved-models/model-evn-123-MNIST-[0.8, 0.2]-123-conv-[28, 28, 1]-10-[64, 64, 64]-5-None-10-5-2-64-0.0001-UMSE-None-None',\n",
       " 'result_path': '../saved-results/results-evn-123-MNIST-[0.8, 0.2]-123-conv-[28, 28, 1]-10-[64, 64, 64]-5-None-10-5-2-64-0.0001-UMSE-None-None',\n",
       " 'train_losses': [],\n",
       " 'val_losses': [83.00633658854167,\n",
       "  1.280894760131836,\n",
       "  1.0151653238932292,\n",
       "  0.9861272176106771,\n",
       "  0.9812116190592448],\n",
       " 'train_accuracies': [],\n",
       " 'val_accuracies': [0.9190000295639038,\n",
       "  0.8945833444595337,\n",
       "  0.9087499976158142,\n",
       "  0.9165833592414856,\n",
       "  0.9211666584014893],\n",
       " 'fail_trace': <function seml.evaluation.get_results(db_collection_name, fields=None, to_data_frame=False, mongodb_config=None, states=None, filter_dict=None, parallel=False)>,\n",
       " 'accuracy': array(0.9235),\n",
       " 'confidence_aleatoric_apr': 0.9870992978751494,\n",
       " 'confidence_epistemic_apr': 0.9836007151096335,\n",
       " 'confidence_aleatoric_auroc': 0.8799443011277783,\n",
       " 'confidence_epistemic_auroc': 0.8557960444600147,\n",
       " 'brier_score': array(0.9354863, dtype=float32),\n",
       " 'anomaly_detection_aleatoric_KMNIST_apr': 0.8374005823570237,\n",
       " 'anomaly_detection_epistemic_KMNIST_apr': 0.617183776047515,\n",
       " 'anomaly_detection_aleatoric_KMNIST_auroc': 0.860807565,\n",
       " 'anomaly_detection_epistemic_KMNIST_auroc': 0.7062649599999999,\n",
       " 'anomaly_detection_aleatoric_FMNIST_apr': 0.6742174542819779,\n",
       " 'anomaly_detection_epistemic_FMNIST_apr': 0.463559273168947,\n",
       " 'anomaly_detection_aleatoric_FMNIST_auroc': 0.7320367400000001,\n",
       " 'anomaly_detection_epistemic_FMNIST_auroc': 0.51712821}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=123\n",
    "dataset_name='MNIST'\n",
    "ood_dataset_names=['KMNIST', 'FMNIST']\n",
    "split=[.8, .2]\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='../saved-models'\n",
    "architecture='conv'\n",
    "input_dims=[28, 28, 1]\n",
    "output_dim=10\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=5\n",
    "k_lipschitz=None\n",
    "\n",
    "# Training parameters\n",
    "directory_results='../saved-results'\n",
    "max_epochs=10\n",
    "patience=5\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=1e-4\n",
    "loss='UMSE'\n",
    "adversarial_training = {'shared': {'attack_name': 'PGD_L2',\n",
    "                                   'attack_loss': 'crossentropy',\n",
    "                                   'bounds': [0., 1.],\n",
    "                                   'criterion_params': {'threshold': None,\n",
    "                                                        'start_data': 'in'},\n",
    "                                   'attack_params': {'epsilons': [1.0],\n",
    "                                                     'loss_name': 'crossentropy',\n",
    "                                                     'punished_measure': None,\n",
    "                                                     'data_type': 'in'},\n",
    "                                   'attack_kwargs': {'steps': 5}}}\n",
    "rs_sigma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-08 15:49:32 (INFO): Received the following configuration:\n",
      "2021-06-08 15:49:32 (INFO): DATASET | seed_dataset 123 - dataset_name MNIST - ood_dataset_names ['KMNIST', 'FMNIST'] - split [0.8, 0.2]\n",
      "2021-06-08 15:49:32 (INFO): ARCHITECTURE |  seed_model 123 -  architecture conv -  input_dims [28, 28, 1] -  output_dim 10 -  hidden_dims [64, 64, 64] -  kernel_dim 5 -  k_lipschitz None\n",
      "2021-06-08 15:49:32 (INFO): TRAINING |  max_epochs 10 -  patience 5 -  frequency 2 -  batch_size 64 -  lr 0.0001 -  loss UMSE\n",
      "2021-06-08 15:49:32 (INFO): shared: {'attack_name': 'PGD_L2', 'attack_loss': 'crossentropy', 'bounds': [0.0, 1.0], 'criterion_params': {'threshold': None, 'start_data': 'in'}, 'attack_params': {'epsilons': [1.0], 'loss_name': 'crossentropy', 'punished_measure': None, 'data_type': 'in'}, 'attack_kwargs': {'steps': 5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 67.793 | Val Acc.: 0.936\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 1.298 | Val Acc.: 0.835\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 1.016 | Val Acc.: 0.93\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 0.987 | Val Acc.: 0.94\n",
      "Model saved\n",
      "Epoch 8 -> Val loss 0.981 | Val Acc.: 0.945\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "results = run(\n",
    "        # Dataset parameters\n",
    "        seed_dataset,  # Seed to shuffle dataset. int\n",
    "        dataset_name,  # Dataset name. string\n",
    "        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "        split,  # Split for train/val/test sets. list of floats\n",
    "\n",
    "        # Architecture parameters\n",
    "        seed_model,  # Seed to init model. int\n",
    "        directory_model,  # Path to save model. string\n",
    "        architecture,  # Encoder architecture name. string\n",
    "        input_dims,  # Input dimension. List of ints\n",
    "        output_dim,  # Output dimension. int\n",
    "        hidden_dims,  # Hidden dimensions. list of ints\n",
    "        kernel_dim,  # Input dimension. int\n",
    "        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "\n",
    "        # Training parameters\n",
    "        directory_results,  # Path to save resutls. string\n",
    "        max_epochs,  # Maximum number of epochs for training\n",
    "        patience,  # Patience for early stopping. int\n",
    "        frequency,  # Frequency for early stopping test. int\n",
    "        batch_size,  # Batch size. int\n",
    "        lr,  # Learning rate. float\n",
    "        loss,  # Loss name. string\n",
    "        adversarial_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '../saved-models/model-evn-123-MNIST-[0.8, 0.2]-123-conv-[28, 28, 1]-10-[64, 64, 64]-5-None-10-5-2-64-0.0001-UMSE-PGD_L2-crossentropy-[0.0, 1.0]-None-in-[1.0]-crossentropy-None-in-5-None',\n",
       " 'result_path': '../saved-results/results-evn-123-MNIST-[0.8, 0.2]-123-conv-[28, 28, 1]-10-[64, 64, 64]-5-None-10-5-2-64-0.0001-UMSE-PGD_L2-crossentropy-[0.0, 1.0]-None-in-[1.0]-crossentropy-None-in-5-None',\n",
       " 'train_losses': [],\n",
       " 'val_losses': [67.792509765625,\n",
       "  1.2979625345865886,\n",
       "  1.0164786885579427,\n",
       "  0.9867632039388021,\n",
       "  0.9806141916910808],\n",
       " 'train_accuracies': [],\n",
       " 'val_accuracies': [0.9357500076293945,\n",
       "  0.8345000147819519,\n",
       "  0.9299166798591614,\n",
       "  0.9398333430290222,\n",
       "  0.9445833563804626],\n",
       " 'fail_trace': <function seml.evaluation.get_results(db_collection_name, fields=None, to_data_frame=False, mongodb_config=None, states=None, filter_dict=None, parallel=False)>,\n",
       " 'accuracy': array(0.947),\n",
       " 'confidence_aleatoric_apr': 0.9945739525922987,\n",
       " 'confidence_epistemic_apr': 0.9930451094215458,\n",
       " 'confidence_aleatoric_auroc': 0.9211296846048096,\n",
       " 'confidence_epistemic_auroc': 0.9063410770855332,\n",
       " 'brier_score': array(0.9338521, dtype=float32),\n",
       " 'anomaly_detection_aleatoric_KMNIST_apr': 0.8720596870622846,\n",
       " 'anomaly_detection_epistemic_KMNIST_apr': 0.663338536306276,\n",
       " 'anomaly_detection_aleatoric_KMNIST_auroc': 0.899715005,\n",
       " 'anomaly_detection_epistemic_KMNIST_auroc': 0.7694926700000001,\n",
       " 'anomaly_detection_aleatoric_FMNIST_apr': 0.5709774195699228,\n",
       " 'anomaly_detection_epistemic_FMNIST_apr': 0.39201199338553594,\n",
       " 'anomaly_detection_aleatoric_FMNIST_auroc': 0.6432549750000001,\n",
       " 'anomaly_detection_epistemic_FMNIST_auroc': 0.35845485}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
